# LibrasLive ðŸ¤Ÿ

**Real-time LIBRAS Sign Language Translator**

LibrasLive Ã© um sistema de traduÃ§Ã£o em tempo real para LIBRAS (LÃ­ngua Brasileira de Sinais) que converte sinais das mÃ£os capturados pela webcam em texto e Ã¡udio. O sistema reconhece o alfabeto LIBRAS (A-Y, excluindo J e Z) e 20 frases mais comuns.

![LibrasLive Demo](https://img.shields.io/badge/Status-Active-green) ![Python](https://img.shields.io/badge/Python-3.8+-blue) ![JavaScript](https://img.shields.io/badge/JavaScript-ES6-yellow) ![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-red)

## ðŸŒŸ Funcionalidades

- âœ… **Reconhecimento de Alfabeto**: 24 letras do alfabeto LIBRAS (A-Y, excluindo J e Z)
- âœ… **Reconhecimento de Frases**: 20 frases mais comuns em LIBRAS
- âœ… **Tempo Real**: LatÃªncia < 1 segundo para interaÃ§Ã£o fluida
- âœ… **Interface Web**: Interface moderna e responsiva
- âœ… **SÃ­ntese de Voz**: TTS (Text-to-Speech) com gTTS e pyttsx3
- âœ… **BotÃ£o Repetir**: Reproduz novamente o Ã¡udio da Ãºltima traduÃ§Ã£o
- âœ… **VisualizaÃ§Ã£o de Landmarks**: Exibe pontos de referÃªncia da mÃ£o (opcional)
- âœ… **MÃ©tricas em Tempo Real**: FPS, latÃªncia e prediÃ§Ãµes por minuto
- âœ… **HistÃ³rico de TraduÃ§Ãµes**: MantÃ©m registro das Ãºltimas traduÃ§Ãµes

## ðŸ“‹ Requisitos do Sistema

### Hardware
- **Webcam**: CÃ¢mera com resoluÃ§Ã£o mÃ­nima de 640x480
- **Processador**: CPU multi-core (recomendado: 4+ cores)
- **MemÃ³ria**: 4GB RAM mÃ­nimo, 8GB recomendado
- **GPU**: Opcional (CUDA para acelerar inferÃªncia)

### Software
- **Python**: 3.8 ou superior
- **Node.js**: 14.0+ (opcional, para desenvolvimento frontend)
- **Navegador**: Chrome 80+, Firefox 75+, Safari 13+, Edge 80+

## ðŸš€ InstalaÃ§Ã£o RÃ¡pida

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/libras-live.git
cd libras-live
```

### 2. Instale DependÃªncias Python
"
```bash
cd backend
pip install -r requirements.txt
```

### 3. Execute o Backend

```bash
python app.py
```

### 4. Abra o Frontend

Navegue atÃ© `frontend/index.html` no seu navegador ou sirva via servidor web:

```bash
# OpÃ§Ã£o 1: Abrir diretamente
# Abrir frontend/index.html no navegador

# OpÃ§Ã£o 2: Servidor Python simples
cd frontend
python -m http.server 8000
# Acesse http://localhost:8000
```

## ðŸ“ Estrutura do Projeto

```
libras-live/
â”œâ”€â”€ backend/                    # Backend Python (Flask + SocketIO)
â”‚   â”œâ”€â”€ app.py                 # Servidor principal
â”‚   â”œâ”€â”€ infer.py               # Motor de inferÃªncia dos modelos
â”‚   â”œâ”€â”€ tts.py                 # MÃ³dulo de sÃ­ntese de voz
â”‚   â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”‚   â””â”€â”€ models/                # Modelos treinados
â”‚       â”œâ”€â”€ alphabet_model.pt  # Modelo do alfabeto
â”‚       â””â”€â”€ phrase_model.pt    # Modelo de frases
â”œâ”€â”€ frontend/                  # Frontend Web (HTML/CSS/JS)
â”‚   â”œâ”€â”€ index.html            # Interface principal
â”‚   â”œâ”€â”€ main.js               # LÃ³gica JavaScript + MediaPipe
â”‚   â””â”€â”€ styles.css            # Estilos CSS
â”œâ”€â”€ data/                     # Datasets e documentaÃ§Ã£o
â”‚   â”œâ”€â”€ datasets_publicos.txt # Fontes dos datasets
â”‚   â””â”€â”€ landmarks/            # Landmarks extraÃ­dos (opcional)
â”œâ”€â”€ notebooks/                # Notebooks de treinamento
â”‚   â”œâ”€â”€ train_alphabet.ipynb  # Treinamento do modelo alfabeto
â”‚   â””â”€â”€ train_phrase.ipynb    # Treinamento do modelo frases
â”œâ”€â”€ Dockerfile               # ContainerizaÃ§Ã£o (opcional)
â””â”€â”€ README.md               # Este arquivo
```

## ðŸŽ¯ Uso do Sistema

### Iniciando o Sistema

1. **Inicie o Backend**:
   ```bash
   cd backend
   python app.py
   ```
   O servidor estarÃ¡ disponÃ­vel em `http://localhost:5000`

2. **Abra o Frontend**:
   - Navegue atÃ© `frontend/index.html` no navegador
   - Ou use um servidor web local

### Usando a Interface

1. **PermissÃµes da CÃ¢mera**: Autorize o acesso Ã  webcam quando solicitado
2. **Iniciar Captura**: Clique em "Iniciar CÃ¢mera"
3. **Fazer Sinais**: Posicione a mÃ£o na frente da cÃ¢mera e faÃ§a sinais LIBRAS
4. **Ver TraduÃ§Ã£o**: O texto traduzido aparecerÃ¡ em tempo real
5. **Ouvir Ãudio**: O sistema reproduzirÃ¡ automaticamente o Ã¡udio da traduÃ§Ã£o
6. **Repetir Som**: Use o botÃ£o "Repetir Som" para ouvir novamente

### Sinais Suportados

#### Alfabeto LIBRAS (24 letras)
```
A B C D E F G H I K L M N O P Q R S T U V W X Y
```
*Nota: J e Z nÃ£o sÃ£o suportadas pois requerem movimento*

#### Frases Comuns (20 frases)
- **Cumprimentos**: OlÃ¡, Tchau, AtÃ© logo
- **Cortesia**: Obrigado, Por favor, Desculpa
- **Respostas**: Sim, NÃ£o, Tudo bem
- **SaudaÃ§Ãµes**: Bom dia, Boa tarde, Boa noite
- **ExpressÃµes**: Eu te amo
- **Substantivos**: FamÃ­lia, Casa, Trabalho, Escola, Ãgua, Comida
- **Pedidos**: Ajuda

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` no diretÃ³rio `backend/`:

```env
# ConfiguraÃ§Ãµes do Servidor
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_DEBUG=False

# ConfiguraÃ§Ãµes TTS
TTS_ENGINE=gtts  # ou pyttsx3
TTS_LANGUAGE=pt
TTS_CACHE_SIZE=50

# ConfiguraÃ§Ãµes do Modelo
MODEL_CONFIDENCE_THRESHOLD=0.3
PHRASE_CONFIDENCE_THRESHOLD=0.4
TEMPORAL_SMOOTHING=True
PREDICTION_COOLDOWN=1.0
```

### ParÃ¢metros de InferÃªncia

Edite `backend/app.py` para ajustar:

```python
# SuavizaÃ§Ã£o temporal
STABILITY_THRESHOLD = 0.6  # 60% das prediÃ§Ãµes devem ser iguais
MIN_PREDICTIONS = 5        # MÃ­nimo de prediÃ§Ãµes antes da decisÃ£o
PREDICTION_COOLDOWN = 1.0  # Segundos entre prediÃ§Ãµes
```

### ConfiguraÃ§Ãµes MediaPipe

Edite `frontend/main.js`:

```javascript
hands.setOptions({
    maxNumHands: 1,              // MÃ¡ximo de mÃ£os
    modelComplexity: 1,          // Complexidade do modelo (0-2)
    minDetectionConfidence: 0.7, // ConfianÃ§a mÃ­nima detecÃ§Ã£o
    minTrackingConfidence: 0.5   // ConfianÃ§a mÃ­nima rastreamento
});
```

## ðŸ§  Treinamento dos Modelos

### Preparar Ambiente

```bash
cd notebooks
pip install jupyter notebook
jupyter notebook
```

### Treinar Modelo do Alfabeto

1. Abra `train_alphabet.ipynb`
2. Execute todas as cÃ©lulas em ordem
3. O modelo serÃ¡ salvo em `backend/models/alphabet_model.pt`

### Treinar Modelo de Frases

1. Abra `train_phrase.ipynb`
2. Execute todas as cÃ©lulas em ordem
3. O modelo serÃ¡ salvo em `backend/models/phrase_model.pt`

### Datasets

Os notebooks utilizam datasets sintÃ©ticos por padrÃ£o. Para usar datasets reais:

1. Baixe os datasets pÃºblicos documentados em `data/datasets_publicos.txt`
2. Modifique as seÃ§Ãµes de carregamento de dados nos notebooks
3. Re-execute o treinamento

## ðŸ³ Docker (Opcional)

### Construir Imagem

```bash
docker build -t libras-live .
```

### Executar Container

```bash
docker run -p 5000:5000 -p 8000:8000 libras-live
```

### Docker Compose

```yaml
version: '3.8'
services:
  libras-live:
    build: .
    ports:
      - "5000:5000"
      - "8000:8000"
    volumes:
      - ./backend/models:/app/backend/models
```

## ðŸ”§ SoluÃ§Ã£o de Problemas

### Problemas Comuns

#### 1. CÃ¢mera nÃ£o funciona
```bash
# Verificar permissÃµes do navegador
# Chrome: chrome://settings/content/camera
# Firefox: about:preferences#privacy
```

#### 2. Modelos nÃ£o carregam
```bash
# Verificar se os arquivos existem
ls -la backend/models/
# Executar notebooks de treinamento se necessÃ¡rio
```

#### 3. SocketIO nÃ£o conecta
```bash
# Verificar se o backend estÃ¡ rodando
curl http://localhost:5000
# Verificar firewall/proxy
```

#### 4. TTS nÃ£o funciona
```bash
# Instalar dependÃªncias TTS
pip install gtts pyttsx3
# Verificar conexÃ£o internet (para gTTS)
```

### Logs e Debug

```bash
# Backend logs
cd backend
python app.py --debug

# Frontend logs
# Abrir DevTools no navegador (F12)
# Verificar Console e Network tabs
```

### Performance

```bash
# Verificar uso de GPU
python -c "import torch; print(torch.cuda.is_available())"

# Monitor recursos
htop  # Linux/Mac
# Task Manager no Windows
```

## ðŸ“Š MÃ©tricas de Performance

### Benchmarks Esperados

| MÃ©trica | Valor Esperado |
|---------|---------------|
| LatÃªncia Total | < 1000ms |
| FPS MediaPipe | 15-30 fps |
| AcurÃ¡cia Alfabeto | > 85% |
| AcurÃ¡cia Frases | > 75% |
| Tempo InferÃªncia | < 100ms |

### Monitoramento

A interface exibe mÃ©tricas em tempo real:
- **LatÃªncia**: Tempo total de processamento
- **FPS**: Quadros por segundo do MediaPipe
- **PrediÃ§Ãµes/min**: Taxa de reconhecimento

## ðŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Veja como ajudar:

### 1. Reportar Problemas

- Use GitHub Issues para bugs e sugestÃµes
- Inclua logs, screenshots e informaÃ§Ãµes do sistema
- Descreva passos para reproduzir o problema

### 2. Melhorar CÃ³digo

```bash
# Fork do repositÃ³rio
git fork https://github.com/seu-usuario/libras-live

# Criar branch para feature
git checkout -b minha-feature

# Fazer alteraÃ§Ãµes e commits
git add .
git commit -m "Adiciona nova funcionalidade"

# Abrir Pull Request
git push origin minha-feature
```

### 3. Adicionar Dados

- Contribua com novos sinais LIBRAS
- Valide sinais existentes com especialistas
- Melhore datasets sintÃ©ticos

### 4. DocumentaÃ§Ã£o

- Corrija erros na documentaÃ§Ã£o
- Adicione tutoriais e exemplos
- Traduza para outros idiomas

## ðŸ“š Recursos Adicionais

### Aprender LIBRAS
- [Instituto Nacional de EducaÃ§Ã£o de Surdos (INES)](https://www.ines.gov.br/)
- [DicionÃ¡rio de Libras](https://www.dicionariolibras.com.br/)
- [Curso de Libras Online](https://www.cursoslibras.com.br/)

### Tecnologias Utilizadas
- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- [PyTorch](https://pytorch.org/)
- [Flask-SocketIO](https://flask-socketio.readthedocs.io/)
- [gTTS - Google Text-to-Speech](https://pypi.org/project/gTTS/)

### Datasets
- [Sign Language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist)
- [Libras Movement Dataset](https://archive.ics.uci.edu/ml/datasets/libras+movement)

## ðŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ðŸ† Reconhecimentos

- **MediaPipe Team** por fornecer a soluÃ§Ã£o de detecÃ§Ã£o de mÃ£os
- **Comunidade LIBRAS** por recursos educacionais
- **Datasets PÃºblicos** mencionados em `data/datasets_publicos.txt`

## ðŸ“ž Suporte

- **GitHub Issues**: Para bugs e solicitaÃ§Ãµes de recursos
- **Discussions**: Para perguntas gerais e discussÃµes
- **Email**: joao.bruschi@outlook.com.br
- **LinkedIn**: [Via mensagem direta](https://www.linkedin.com/in/joaobruschi/)
  
---

## ðŸš€ Roadmap

### VersÃ£o Atual (v1.0)
- [x] Reconhecimento bÃ¡sico de alfabeto e frases
- [x] Interface web responsiva
- [x] TTS integrado
- [x] MÃ©tricas em tempo real

### PrÃ³ximas VersÃµes

#### v1.1 - Features AvanÃ§adas
- [ ] DetecÃ§Ã£o de duas mÃ£os
- [ ] Sinais com movimento (J, Z)
